{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de programación Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizado para manejos de directorios y rutas\n",
    "import os\n",
    "# Computacion vectorial y cientifica para python\n",
    "import numpy as np\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Necesario para graficar superficies 3D\n",
    "\n",
    "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Regresión lineal con una variable\n",
    "\n",
    "El archivo `Data/ex1data1.txt` contiene el dataset para el problema de regresion lineal. La primera columna es la problacion de una ciudad (en 10,000s) y la segunda columna es el beneficio que genera un camion de comida en esa ciudad (en $10,000s). Un valor negativo indica una perdida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer datos separados por una coma\n",
    "data = np.loadtxt(os.path.join('Datasets', 'ex1data1.txt'), delimiter=',')\n",
    "print(data)\n",
    "x, y = data[:, 0], data[:, 1]\n",
    "m = y.size  # m = numero de ejemplos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Trazar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(x, y):\n",
    "    #Grafica los puntos x e y en una figura nueva. \n",
    "    \n",
    "    #fig = pyplot.figure()  # abre una nueva figura\n",
    "    pyplot.plot(x, y, 'ro', ms=5, mec='g')\n",
    "    color = 'ro'#la o es para que sea puntos\n",
    "    #pyplot.plot(x, y, color='green', marker='x', linestyle='dashed', linewidth=1, markersize=5)\n",
    "    pyplot.ylabel('Beneficio en $10,000')\n",
    "    pyplot.xlabel('Poblacion de una ciudad en 10,000s')\n",
    "plotData(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pyplot.plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"section2\"></a>\n",
    "### 1.2 Descenso por el gradiente\n",
    "\n",
    "#### 1.2.1 Ecuaciones de actualización\n",
    "\n",
    "El objetivo de la regresion lineal es minimizar la funcion de costo\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\left( h_{\\theta}(x^{(i)}) - y^{(i)}\\right)^2$$\n",
    "\n",
    "donde la hipotesis $h_\\theta(x)$ esta dada por el modelo lineal\n",
    "$$ h_\\theta(x) = \\theta^Tx = \\theta_0 + \\theta_1 x_1$$\n",
    "\n",
    "Los parametros del modelo son los valores $\\theta_j$. Estos son los valores que se ajustaran al costo minimo $J(\\theta)$. Un camino para lograr esto es usar el algoritmo por lotes del descenso por el gradiente. En el descenso por el gradiente por lotes, cada iteracion ejecuta una actualizacion \n",
    "$$ \\theta_j = \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)}\\right)x_j^{(i)} \\qquad \\text{actualizacion simultanea } \\theta_j \\text{ for all } j$$\n",
    "\n",
    "Con cada paso del descenso por el gradiente, los parametros $\\theta_j$ son mas cercanos a los valores optimos que permitiran lograr el costo mas bajo J($\\theta$).\n",
    "\n",
    "#### 1.2.2 Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega una columna de unos a x. La funcion stack de numpy une matrices a lo largo de un eje dado.\n",
    "# El primer eje (eje = 0) se refiere a filas (ejemplos de entrenamiento)\n",
    "# y el segundo eje (eje = 1) se refiere a columnas (características).\n",
    "\n",
    "x = np.stack([np.ones(m), x], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "#### 1.2.3 Cálculo del costo $J(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hipotesis(x, thetas):\n",
    "    hipotesis = np.dot(x, thetas)\n",
    "    return hipotesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_costo(x, y, thetas):\n",
    "    m = y.size  # numero de ejemplos de entrenamiento\n",
    "    J = 1/(2 * m) * np.sum(np.square(hipotesis(x, thetas) - y))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de funcionamiento de la funcion de costo con dos valores diferentes de $\\theta$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = funcion_costo(x, y, thetas=np.array([0.0, 0.0]))\n",
    "print('Con thetas = [0, 0]\\nCosto calculado = %.2f' % J)\n",
    "print('Valor de costo esperado (aproximadamente) 32.07\\n')\n",
    "\n",
    "# pruebas adicionales de la función de costes\n",
    "J = funcion_costo(x, y, thetas=np.array([-1, 2]))\n",
    "print('Con thetas = [-1, 2]\\nCosto calculado = %.2f' % J)\n",
    "print('Valor de costo esperado (aproximadamente)  54.24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = funcion_costo(x, y, thetas=np.array([0.9, 0.9]))\n",
    "print('Con thetas = [-1, 2]\\nCosto calculado = %.2f' % J)\n",
    "J = funcion_costo(x, y, thetas=np.array([-3.8958, 1.1664]))\n",
    "print('Con thetas = [-1, 2]\\nCosto calculado = %.2f' % J)\n",
    "J = funcion_costo(x, y, thetas=np.array([-3.6303, 1.1664]))\n",
    "print('Con thetas = [-1, 2]\\nCosto calculado = %.2f' % J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "#### 1.2.4 Descenso por el gradiente\n",
    "\n",
    "El costo $J(\\theta)$ esta parametrizado por el vector $\\theta$, no $X$ y $y$. Donde hay que minimizar el valor de $J(\\theta)$ cambiando los valores del vector $\\theta$. Una buena manera de verificar si el descenso por el gradiente esta trabajando correctamente es ver los valores de $J(\\theta)$ y verificar si estos decresen en cada paso. \n",
    "\n",
    "<div class=\"alert alert-box alert-warning\">\n",
    "**Vectores y matrices en `numpy`** - Importantes notas para implementación\n",
    "Un vector en `numpy` es un array de una diemension, por ejemplo `np.array([1, 2, 3])` es un vector. Una matriz en `numpy` is un arreglo de dos dimensiones, por ejemplo  `np.array([[1, 2, 3], [4, 5, 6]])`. Sin embargo, lo siguiente todavía se considera una matriz `np.array ([[1, 2, 3]])` ya que tiene dos dimensiones, incluso si tiene una forma de 1x3 (que parece un vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desceso_gradiente(x, y, thetas, alpha, num_iters):\n",
    "    # Inicializa algunos valores importantes\n",
    "\n",
    "    m = y.size# numero de ejemplos de entrenamiento\n",
    " \n",
    "    # hace una copia de theta, para evitar cambiar la matriz original, \n",
    "    # ya que las matrices numpy se pasan por referencia a las funciones\n",
    "    thetas = thetas.copy()\n",
    "    J_history = [] # Lista que se utiliza para almacenar el costo en cada iteración\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        thetas = thetas - (alpha / m) * (hipotesis(x, thetas) - y).dot(x)\n",
    "        # save the cost J in every iteration\n",
    "        J_history.append(funcion_costo(x, y, thetas))\n",
    "    return thetas, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicializan los parametros $\\theta$ con 0 y la taza de aprendizaje $\\alpha$ con 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inicializa los parametros de ajuste\n",
    "thetas = np.zeros(2)\n",
    "\n",
    "# configuraciones para el descenso por el gradiente\n",
    "iterations = 10000\n",
    "alpha = 0.003\n",
    "\n",
    "thetas, J_history = desceso_gradiente(x,y, thetas, alpha, iterations)\n",
    "print('Theta encontrada por descenso gradiente: {:.4f}, {:.4f}'.format(*thetas))\n",
    "print('Valores theta esperados (aproximadamente): [-3.6303, 1.1664]')"
   ]
  },
  {
   "source": [
    "Se utilizan los parametros finales para grafical la linea."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grafica la linea de ajuste\n",
    "plotData(x[:, 1], y)\n",
    "pyplot.plot(x[:, 1], hipotesis(x, thetas), '-')\n",
    "pyplot.legend(['Datos de entrenamiento', 'Regresión linear']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores finales de $\\theta$ se utilizaran para realizar predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir valores de beneficio para poblaciones de 35,000 y 70,000\n",
    "predict1 = hipotesis([1, 3.5], thetas)\n",
    "print('Para una población = 35,000, se predice un beneficio de {:.2f}\\n'.format(predict1*10000))\n",
    "\n",
    "predict2 = hipotesis([1, 9], thetas)\n",
    "print('Para una población de = 70,000, se predice un beneficio de {:.2f}\\n'.format(predict2*10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visualizar $J(\\theta)$\n",
    "\n",
    "Para comprender mejor la función de costo $J(\\theta)$, se graficará la funcion de costo en 2 dimenciones con los valores de $\\theta_0$ y $\\theta_1$. \n",
    "\n",
    "El proposito de graficar el costo para observar como $J(\\theta)$ varia con cambios en $\\theta_0$ y $\\theta_1$. La función de costo  $J(\\theta)$ tiene forma de una cuenca con un minimo global. (Esto es mas facil observar en los contornos de una superficie 3D). El minimo es el punto optimo para $\\theta_0$ y $\\theta_1$, en cada paso del descenso por el gradiente se mueve mas cerca a este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuadrícula sobre la que se calcula J\n",
    "theta0_vals = np.linspace(-10, 10, 100)\n",
    "theta1_vals = np.linspace(-1, 4, 100)\n",
    "\n",
    "# inicializa J_vals con una matriz de 0's\n",
    "J_vals = np.zeros((theta0_vals.shape[0], theta1_vals.shape[0]))\n",
    "\n",
    "# Completar J_vals\n",
    "for i, theta0 in enumerate(theta0_vals):\n",
    "    for j, theta1 in enumerate(theta1_vals):\n",
    "        J_vals[i, j] = funcion_costo(x, y, [theta0, theta1])\n",
    "        \n",
    "# Debido a la forma en que funcionan las cuadrículas en el comando surf, \n",
    "# se necesita transponer J_vals antes de llamar a surf, o de lo contrario los ejes se invertirán\n",
    "J_vals = J_vals.T\n",
    "\n",
    "# graficar la superficie\n",
    "fig = pyplot.figure(figsize=(12, 5))\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.plot_surface(theta0_vals, theta1_vals, J_vals, cmap='viridis')\n",
    "pyplot.xlabel('theta0')\n",
    "pyplot.ylabel('theta1')\n",
    "pyplot.title('Surface')\n",
    "\n",
    "# graficar contornos\n",
    "# Grafica J_vals como 15 contours spaciados logaritmicamente entre 0.01 y 100\n",
    "ax = pyplot.subplot(122)\n",
    "pyplot.contour(theta0_vals, theta1_vals, J_vals, linewidths=2, cmap='viridis', levels=np.logspace(-2, 3, 20))\n",
    "pyplot.xlabel('theta0')\n",
    "pyplot.ylabel('theta1')\n",
    "pyplot.plot(thetas[0], thetas[1], 'ro', ms=10, lw=2)\n",
    "pyplot.title('Contorno, mostrando el minimo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd0c569cd2e17f62341e0f08a54f9a867c3c0d3a6f67454072d7de41a8b5dff8343",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "c569cd2e17f62341e0f08a54f9a867c3c0d3a6f67454072d7de41a8b5dff8343"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}